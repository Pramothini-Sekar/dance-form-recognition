# Image Classification on a Self-Curated Dataset of Dance Videos from YouTube

Dance videos contain a lot of information such as people's costumes' colors, number of people, the poses and the speed of dance. A good classifier can be extended to a variety of real-world problems. It can automatically judge the authenticity of a competitive performance or aid a person in identifying a dance type during real-time performances. Whilst previous works concentrate just on CNN-based image classification on video frames, this project aims to run a variety of models to understand the best approach to solve this identification problem. This work aims to use the techniques of Long-Short Term Memory and Temporal CNN to understand how human activity recognition can be utilized to classify dance videos. The Temporal model achieves highest accuracy whilst the pretrained ResNet model shows below-par performance in comparison.

The data set will consist of frames from YouTube videos of each dance form: - ballet, bharatanatyam, break, flamenco, square and waltz. For data preparation, we picked videos of each dance form. These videos were from stage performances for entertainment or performances in a dance competition of the same category. We then extracted frames from these videos at a fixed rate of 2 frames per second of the video. We named the frames with the dance form name and a serial number to later make it easier for us to pick the labels of each frame for training and testing. We created nearly 1000 frames for each dance form collected from nearly 8 videos per dance form.
